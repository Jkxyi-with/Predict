{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4ad4918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7c88637",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/root/lanyun-tmp/prediction/UserBehavior.csv\"\n",
    "output_path = \"/root/lanyun-tmp/prediction/train.csv\"\n",
    "last_day = datetime(2017, 12, 1, 23, 59, 59) \n",
    "required_days = 4\n",
    "batch_size = 50000\n",
    "tmp_folder = \"./tmp_batches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1436d732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 加载数据...\n"
     ]
    }
   ],
   "source": [
    "print(\"🚀 加载数据...\")\n",
    "df = pd.read_csv(input_path, header=None,\n",
    "                 names=[\"user_id\", \"item_id\", \"category_id\", \"behavior_type\", \"timestamp\"])\n",
    "df[\"time\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "df = df[df[\"time\"] <= last_day].copy()\n",
    "df = df.sort_values(\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f98687",
   "metadata": {},
   "source": [
    "Train & Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793767aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 筛选在 last_day 前发生的所有行为记录 ===\n",
    "used_df = df[df[\"time\"] <= last_day].copy()\n",
    "\n",
    "# === 获取每个用户最后一次活跃时间 ===\n",
    "print(\"🔍 判断哪些用户在最后一天前就已连续 ≥ N 天无行为...\")\n",
    "last_active = used_df.groupby(\"user_id\")[\"time\"].max()\n",
    "event_cutoff_time = last_day - timedelta(days=required_days)\n",
    "\n",
    "# 如果最后活跃时间 ≤ 截止时间 ⇒ 表明从 cutoff 后用户就再也没有行为 ⇒ event=1\n",
    "event_series = (last_active <= event_cutoff_time).astype(int).rename(\"event\")\n",
    "\n",
    "# === 特征统计：duration 和行为类型 ===\n",
    "print(\"📊 计算用户特征（duration + 行为分布）...\")\n",
    "user_span = used_df.groupby(\"user_id\")[\"time\"].agg([\"min\", \"max\"]).reset_index()\n",
    "user_span[\"duration\"] = (user_span[\"max\"] - user_span[\"min\"]).dt.days\n",
    "user_span = user_span[[\"user_id\", \"duration\"]]\n",
    "\n",
    "features = used_df.groupby(\"user_id\")[\"behavior_type\"].value_counts().unstack().fillna(0).reset_index()\n",
    "\n",
    "# === 合并保存 ===\n",
    "print(\"💾 合并并保存最终训练数据...\")\n",
    "cox_df = user_span.merge(event_series, on=\"user_id\").merge(features, on=\"user_id\", how=\"left\")\n",
    "cox_df.to_csv(output_path, index=False)\n",
    "\n",
    "# === 输出统计 ===\n",
    "print(f\"✅ 已保存：{output_path}\")\n",
    "print(f\"✅ 流失用户数 (event=1): {(cox_df['event'] == 1).sum()} / {len(cox_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427f48d0",
   "metadata": {},
   "source": [
    "Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205f717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 创建临时文件夹存批次结果 ===\n",
    "os.makedirs(tmp_folder, exist_ok=True)\n",
    "\n",
    "# === 获取所有用户并分批处理 ===\n",
    "user_ids = df[\"user_id\"].unique()\n",
    "print(f\"📦 共 {len(user_ids)} 个用户，将分批处理每批 {batch_size} 个用户\")\n",
    "\n",
    "for i in range(0, len(user_ids), batch_size):\n",
    "    batch_user_ids = user_ids[i:i+batch_size]\n",
    "    print(f\"\\n🚧 正在处理批次 {i//batch_size + 1}（用户 {i} ~ {i+len(batch_user_ids)-1}）...\")\n",
    "\n",
    "    # 当前批次用户的数据\n",
    "    batch_df = df[df[\"user_id\"].isin(batch_user_ids)].copy()\n",
    "\n",
    "    # 获取最后活跃时间\n",
    "    last_active = batch_df.groupby(\"user_id\")[\"time\"].max()\n",
    "    event_cutoff_time = last_day - timedelta(days=required_days)\n",
    "    event_series = (last_active <= event_cutoff_time).astype(int).rename(\"event\")\n",
    "\n",
    "    # duration 统计\n",
    "    user_span = batch_df.groupby(\"user_id\")[\"time\"].agg([\"min\", \"max\"]).reset_index()\n",
    "    user_span[\"duration\"] = (user_span[\"max\"] - user_span[\"min\"]).dt.days\n",
    "    user_span = user_span[[\"user_id\", \"duration\"]]\n",
    "\n",
    "    # 行为类型统计\n",
    "    features = batch_df.groupby(\"user_id\")[\"behavior_type\"].value_counts().unstack().fillna(0).reset_index()\n",
    "\n",
    "    # 合并\n",
    "    cox_df = user_span.merge(event_series, on=\"user_id\").merge(features, on=\"user_id\", how=\"left\")\n",
    "\n",
    "    # 保存临时结果\n",
    "    tmp_file = os.path.join(tmp_folder, f\"tmp_batch_{i//batch_size + 1}.csv\")\n",
    "    cox_df.to_csv(tmp_file, index=False)\n",
    "    print(f\"✅ 批次 {i//batch_size + 1} 已保存：{tmp_file}\")\n",
    "\n",
    "# === 合并所有批次结果 ===\n",
    "print(\"\\n🔗 合并所有批次文件...\")\n",
    "all_parts = [pd.read_csv(os.path.join(tmp_folder, f)) for f in sorted(os.listdir(tmp_folder)) if f.endswith(\".csv\")]\n",
    "final_df = pd.concat(all_parts, ignore_index=True)\n",
    "final_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ 最终训练集已保存：{output_path}\")\n",
    "print(f\"✅ 流失用户数 (event=1): {(final_df['event'] == 1).sum()} / {len(final_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc21cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "125eb1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 特征构建函数 ===\n",
    "def add_user_features(df: pd.DataFrame, window_end_date: str, output_path: str, df_all_behavior: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    df[\"total_actions\"] = df[[\"pv\", \"cart\", \"fav\", \"buy\"]].sum(axis=1)\n",
    "    df[\"action_days\"] = df[\"duration\"] + 1\n",
    "    df[\"avg_actions_per_day\"] = df[\"total_actions\"] / (df[\"action_days\"] + 1e-5)\n",
    "\n",
    "    def compute_entropy(row):\n",
    "        actions = row[[\"pv\", \"cart\", \"fav\", \"buy\"]].values\n",
    "        probs = actions / (actions.sum() + 1e-5)\n",
    "        return entropy(probs)\n",
    "\n",
    "    df[\"behavior_entropy\"] = df.apply(compute_entropy, axis=1)\n",
    "\n",
    "    # 计算 recency（仅限截止日期前的行为）\n",
    "    cutoff = pd.to_datetime(window_end_date)\n",
    "    last_time = df_all_behavior[df_all_behavior[\"time\"] <= cutoff].groupby(\"user_id\")[\"time\"].max().reset_index()\n",
    "    last_time[\"recency\"] = (cutoff - last_time[\"time\"]).dt.days\n",
    "    df = df.merge(last_time[[\"user_id\", \"recency\"]], on=\"user_id\", how=\"left\")\n",
    "    df[\"recency\"] = df[\"recency\"].fillna(df[\"duration\"])\n",
    "\n",
    "    # 特征归一化\n",
    "    cols_to_scale = [\"duration\", \"total_actions\", \"action_days\", \"avg_actions_per_day\", \"behavior_entropy\", \"recency\"]\n",
    "    scaler = MinMaxScaler()\n",
    "    df[[col + \"_scaled\" for col in cols_to_scale]] = scaler.fit_transform(df[cols_to_scale])\n",
    "\n",
    "    # 保存文件\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ 特征已保存至：{output_path}，包含用户数：{len(df)}\")\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c093be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 特征已保存至：cox_train_with_features.csv，包含用户数：987984\n",
      "✅ 特征已保存至：cox_val_with_features.csv，包含用户数：987992\n",
      "✅ 特征已保存至：cox_test_with_features.csv，包含用户数：987994\n",
      "   user_id  duration  event  buy  cart  fav     pv  total_actions  \\\n",
      "0        1         7      0  0.0   0.0  0.0   44.0           44.0   \n",
      "1        2         5      0  3.0   0.0  7.0   27.0           37.0   \n",
      "2        3         6      0  0.0  14.0  5.0   22.0           41.0   \n",
      "3        4         6      0  4.0  13.0  0.0  248.0          265.0   \n",
      "4        5         4      0  0.0   0.0  0.0   58.0           58.0   \n",
      "\n",
      "   action_days  avg_actions_per_day  behavior_entropy  recency  \\\n",
      "0            8             5.499993          0.000000      0.0   \n",
      "1            6             6.166656          0.748626      1.0   \n",
      "2            7             5.857134          0.957549      0.0   \n",
      "3            7            37.857089          0.273240      0.0   \n",
      "4            5            11.599977          0.000000      0.0   \n",
      "\n",
      "   duration_scaled  total_actions_scaled  action_days_scaled  \\\n",
      "0         0.000166              0.054777            0.000166   \n",
      "1         0.000118              0.045860            0.000118   \n",
      "2         0.000142              0.050955            0.000142   \n",
      "3         0.000142              0.336306            0.000142   \n",
      "4         0.000095              0.072611            0.000095   \n",
      "\n",
      "   avg_actions_per_day_scaled  behavior_entropy_scaled  recency_scaled  \n",
      "0                    0.017405                 0.000000        0.000000  \n",
      "1                    0.019514                 0.540019        0.010638  \n",
      "2                    0.018535                 0.690726        0.000000  \n",
      "3                    0.119802                 0.197101        0.000000  \n",
      "4                    0.036709                 0.000000        0.000000  \n"
     ]
    }
   ],
   "source": [
    "# === 执行构建：Train / Val / Test ===\n",
    "train_df = pd.read_csv(\"data/train_u.csv\")\n",
    "val_df = pd.read_csv(\"data/valid_u.csv\")\n",
    "test_df = pd.read_csv(\"data/test_u.csv\")\n",
    "\n",
    "train_out = add_user_features(train_df, \"2017-12-01\", \"cox_train_with_features.csv\", df)\n",
    "val_out = add_user_features(val_df, \"2017-12-02\", \"cox_val_with_features.csv\", df)\n",
    "test_out = add_user_features(test_df, \"2017-12-03\", \"cox_test_with_features.csv\", df)\n",
    "\n",
    "# 示例输出\n",
    "print(train_out.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2a869ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 集合: event=1 数量 = 20716 / 987984 (2.10%)\n",
      "Val 集合: event=1 数量 = 4495 / 987992 (0.45%)\n",
      "Test 集合: event=1 数量 = 2169 / 987994 (0.22%)\n"
     ]
    }
   ],
   "source": [
    "# === 输出每个数据集中 event=1 的用户数量和比例 ===\n",
    "for name, df in zip([\"Train\", \"Val\", \"Test\"], [train_out, val_out, test_out]):\n",
    "    event1 = (df[\"event\"] == 1).sum()\n",
    "    total = len(df)\n",
    "    print(f\"{name} 集合: event=1 数量 = {event1} / {total} ({event1/total:.2%})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
